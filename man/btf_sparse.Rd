% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mcmc_samplers.R
\name{btf_sparse}
\alias{btf_sparse}
\title{Run the MCMC for sparse Bayesian trend filtering}
\usage{
btf_sparse(
  y,
  evol_error = "DHS",
  zero_error = "DHS",
  D = 2,
  obsSV = "const",
  nsave = 1000,
  nburn = 1000,
  nskip = 4,
  mcmc_params = list("mu", "yhat", "evol_sigma_t2", "obs_sigma_t2", "zero_sigma_t2",
    "dhs_phi", "dhs_mean", "dhs_phi_zero", "dhs_mean_zero", "h", "h_smooth"),
  computeDIC = TRUE,
  verbose = TRUE,
  D_asv = 1,
  evol_error_asv = "HS",
  nugget_asv = TRUE
)
}
\arguments{
\item{y}{the \code{T x 1} vector of time series observations}

\item{evol_error}{the evolution error distribution; must be one of
'DHS' (dynamic horseshoe prior), 'HS' (horseshoe prior), 'BL' (Bayesian lasso), or 'NIG' (normal-inverse-gamma prior)}

\item{zero_error}{the shrinkage-to-zero distribution; must be one of
'DHS' (dynamic horseshoe prior), 'HS' (horseshoe prior), 'BL' (Bayesian lasso), or 'NIG' (normal-inverse-gamma prior)}

\item{D}{degree of differencing (D = 1, or D = 2)}

\item{obsSV}{Options for modeling the error variance. It must be one of the following:
\itemize{
\item const: Constant error variance for all time points.
\item SV: Stochastic Volatility model.
\item ASV: Adaptive Stochastic Volatility model.
}}

\item{nsave}{number of MCMC iterations to record}

\item{nburn}{number of MCMC iterations to discard (burnin-in)}

\item{nskip}{number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw}

\item{mcmc_params}{named list of parameters for which we store the MCMC output;
must be one or more of:
\itemize{
\item "mu" (conditional mean)
\item "yhat" (posterior predictive distribution)
\item "evol_sigma_t2" (evolution error variance)
\item "zero_sigma_t2" (shrink-to-zero error variance)
\item "obs_sigma_t2" (observation error variance)
\item "dhs_phi" (DHS AR(1) coefficient for evolution error)
\item "dhs_mean" (DHS AR(1) unconditional mean for evolution error)
\item "dhs_phi_zero" (DHS AR(1) coefficient for shrink-to-zero error)
\item "dhs_mean_zero" (DHS AR(1) unconditional mean for shrink-to-zero error)
\item "h" (log variances or log of \code{"obs_sigma_t2"}. Only used when \code{obsSV = "ASV"})
\item "h_smooth" (smooth estimate of log variances. Only used when \code{obsSV = "ASV"} and \code{nugget_asv = TRUE})
}}

\item{computeDIC}{logical; if TRUE, compute the deviance information criterion \code{DIC}
and the effective number of parameters \code{p_d}}

\item{verbose}{logical; should R report extra information on progress?}

\item{D_asv}{integer; degree of differencing (0, 1, or 2) for the ASV model. Only used when \code{obsSV = "ASV"}.}

\item{evol_error_asv}{character; evolution error distribution for the ASV model. Must be one of the five options used in \code{evol_error}. Only used when \code{obsSV = "ASV"}.}

\item{nugget_asv}{logical; if \code{TRUE}, fits the nugget variant of the ASV model. Only used when \code{obsSV = "ASV"}.}
}
\value{
A named list of the \code{nsave} MCMC samples for the parameters named in \code{mcmc_params}
}
\description{
Sparse Bayesian trend filtering has two penalties:
(1) a penalty on the first (D = 1) or second (D = 2) differences of the conditional expectation and
(2) a penalty on the conditional expectation, i.e., shrinkage to zero.
}
\details{
Each penalty is determined by a prior, which include:
\itemize{
\item the dynamic horseshoe prior ('DHS');
\item the static horseshoe prior ('HS');
\item the Bayesian lasso ('BL');
\item the normal stochastic volatility model ('SV');
\item the normal-inverse-gamma prior ('NIG').
}
In each case, the prior is a scale mixture of Gaussians.
Sampling is accomplished with a (parameter-expanded) Gibbs sampler,
mostly relying on a dynamic linear model representation.
}
\note{
The data \code{y} may contain NAs, which will be treated with a simple imputation scheme
via an additional Gibbs sampling step. In general, rescaling \code{y} to have unit standard
deviation is recommended to avoid numerical issues.
}
\examples{
\dontrun{
# TODO: add dsp class or change to use dsp_fit (don't export)
# Example 1: Bumps Data
y = make_signal(name = "bumps", n = 128, snr = 7)

out = btf_sparse(y)
#plot_fitted(y, mu = colMeans(out$mu), postY = out$yhat)

# Example 2: Doppler Data; longer series, more noise
y = make_signal(name = "doppler", n = 500, snr = 7)

out = btf_sparse(y)
#plot_fitted(y, mu = colMeans(out$mu), postY = out$yhat)

# And examine the AR(1) parameters for the log-volatility w/ traceplots:
plot(as.ts(out$dhs_phi)) # AR(1) coefficient
plot(as.ts(out$dhs_mean)) # Unconditional mean

# Example 3: Blocks data (locally constant)
y = make_signal(name = "blocks", n = 1000, snr = 3)

out = btf_sparse(y, D = 1) # try D = 1 to approximate the locally constant behavior
#plot_fitted(y, mu = colMeans(out$mu), postY = out$yhat)
}

}
